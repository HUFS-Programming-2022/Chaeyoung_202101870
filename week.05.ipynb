{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import*\n",
    "nltk.download('book',quiet =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63560ed9",
   "metadata": {},
   "source": [
    "# 반복문 \n",
    "- 반복문의 종류: for문 / while문\n",
    "\n",
    "### while문\n",
    "- 정의:특정 조건을 주고 그 조건이 만족하는 동안 계속해서 반복 수행을 하는 것\n",
    "- 문법구조: while 반복 조건:\n",
    "                    반복 문장\n",
    "  => '반복 조건'이 만족하는 동안 '반복 문장'을 실행\n",
    "- 반복 수행 중 어느 순간 반복 조건에 불만족하면 while문을 빠져나간다는 점에 유의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2ff52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello hufs\n",
      "hello hufs\n",
      "hello hufs\n",
      "hello hufs\n",
      "hello hufs\n"
     ]
    }
   ],
   "source": [
    "#연습코드\n",
    "i = 0\n",
    "while i < 5:\n",
    "    print(\"hello hufs\")\n",
    "    i += 1\n",
    "#코드설명\n",
    "#i 변수를 0으로 초기화시키고, while문의 반복조건으로 i가 5보다 작은지를 검사함. 콜론(:)붙이는 것을 꼭 기억!\n",
    "#while문의 반복수행 시, 1씩 변수가 증가함. 그래야만 while문에서 어느 순간 빠져나가는 경우가 발생하기 때문! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b1d0e",
   "metadata": {},
   "source": [
    "## for과 while의 구분\n",
    "- for: 반복 횟수를 정확히 알고 있으며, 횟수의 변화가 없을 때\n",
    "    ex)전체 학생 성적 산출\n",
    "- while: 반복 횟수가 정확하지 않고, 어떤 조건을 만족시킬 때 반복문을 종료하고 싶은 경우\n",
    "    ex)가위바위보를 이기면 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62185c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204b6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "while j < 5:\n",
    "    print(j)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2a8fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "words = ['apple','banana']\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b011021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "words = ['apple','banana']\n",
    "word = 0\n",
    "while word < 2:\n",
    "    print(words[word])\n",
    "    word += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06ca15",
   "metadata": {},
   "source": [
    "## 반복문의 제어\n",
    "- 반복문의 제어 기능을 사용하는 것은 의도치 않게 코드를 종료시키는 불상사를 발생시킬 수 있기에, 제어는 되도록 사용하지 않도록 함!\n",
    "- break:반복문을 종료시키는 역할\n",
    "  반복문 안에서 break문을 사용하게 되면 현재 수행하고 있는 반복문을 빠져나가겠다는 의미\n",
    "- continue:반목을 수행하는 과정 중에 생략하고 넘어가고 싶은 것이 있을 때 사용함\n",
    "- else:어떤 조건이 \"완전히\" 종료될때, 한번 더 실행하는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e40712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for j in range(7):\n",
    "    if j == 3:break\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ddef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "while j < 3:\n",
    "    print(j)\n",
    "    if j == 2: break \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d622682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(15):\n",
    "    if n == 7:\n",
    "        break\n",
    "else:\n",
    "    print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806b7afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for n in range(15):\n",
    "    if n == 7:\n",
    "        continue\n",
    "else:\n",
    "    print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dffca",
   "metadata": {},
   "source": [
    "#### 구구단 출력코드\n",
    "- for/while 둘 중 하나를 선택한 뒤, 구구단 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d336192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 단까지?: 2\n",
      "===2단===\n",
      "2x1=2\n",
      "2x2=4\n",
      "2x3=6\n",
      "2x4=8\n",
      "2x5=10\n",
      "2x6=12\n",
      "2x7=14\n",
      "2x8=16\n",
      "2x9=18\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "n = int(input('몇 단까지?: '))\n",
    "for i in range(2,n+1):\n",
    "    print(f'==={i}단===')\n",
    "    for j in range(1,10):\n",
    "        print(f'{i}x{j}={i*j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f7aca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇단까지?:5\n",
      "=== 5단 ===\n",
      "5*1 = 5\n",
      "5*2 = 10\n",
      "5*3 = 15\n",
      "5*4 = 20\n",
      "5*5 = 25\n",
      "5*6 = 30\n",
      "5*7 = 35\n",
      "5*8 = 40\n",
      "5*9 = 45\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"몇단까지?:\"))\n",
    "print(f'=== {n}단 ===')\n",
    "i = 1\n",
    "while i < 10:\n",
    "    print(f'{n}*{i} = {n*i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45593313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8257d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ed6c87",
   "metadata": {},
   "source": [
    "## print formating\n",
    "1. f.string\n",
    "- f 혹은 F 둘다 사용 가능\n",
    "- F'{var}'\n",
    "2. format\n",
    "- '{}', format(var)\n",
    "3. %\n",
    "- '%type' %var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13371d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나의 학교는 hufs\n"
     ]
    }
   ],
   "source": [
    "university = 'hufs'\n",
    "print(f'나의 학교는 {university}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81aed8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나의 학교는 hufs입니다.\n"
     ]
    }
   ],
   "source": [
    "print('나의 학교는 %s입니다.'%university)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa30d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나의 학교는 hufs ???\n"
     ]
    }
   ],
   "source": [
    "print('나의 학교는 {} ???' .format(university))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2723872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나의 학교는 university='hufs'!!!\n"
     ]
    }
   ],
   "source": [
    "print(f'나의 학교는 {university=}!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763b022",
   "metadata": {},
   "source": [
    "### NLTK : Corpus\n",
    "- 다양한 종류의 코퍼스가 있음.\n",
    "- 더 다양한 언어 분석이 가능함.\n",
    "\n",
    "-종류\n",
    "- gutenberg\n",
    "- borwm\n",
    "- inaugural\n",
    "\n",
    "-함수 \n",
    "-words()\n",
    "-sents()\n",
    "-fileids()\n",
    "-raw()\n",
    "\n",
    "### gutenberg\n",
    "- 구텐버그의 각 파일을 돌아가면서 글자 수, 단어 수, 문장 수를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dbe975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download('gutenberg', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11375768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PlaintextCorpusReader in 'C:\\\\Users\\\\Owner\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\gutenberg'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63ae94bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b69e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'], ['VOLUME', 'I'], ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f7a0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d8ba20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621613"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4ab3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt\n",
      "192427\n",
      "7752\n",
      "887071\n",
      "austen-persuasion.txt\n",
      "98171\n",
      "3747\n",
      "466292\n",
      "austen-sense.txt\n",
      "141576\n",
      "4999\n",
      "673022\n",
      "bible-kjv.txt\n",
      "1010654\n",
      "30103\n",
      "4332554\n",
      "blake-poems.txt\n",
      "8354\n",
      "438\n",
      "38153\n",
      "bryant-stories.txt\n",
      "55563\n",
      "2863\n",
      "249439\n",
      "burgess-busterbrown.txt\n",
      "18963\n",
      "1054\n",
      "84663\n",
      "carroll-alice.txt\n",
      "34110\n",
      "1703\n",
      "144395\n",
      "chesterton-ball.txt\n",
      "96996\n",
      "4779\n",
      "457450\n",
      "chesterton-brown.txt\n",
      "86063\n",
      "3806\n",
      "406629\n",
      "chesterton-thursday.txt\n",
      "69213\n",
      "3742\n",
      "320525\n",
      "edgeworth-parents.txt\n",
      "210663\n",
      "10230\n",
      "935158\n",
      "melville-moby_dick.txt\n",
      "260819\n",
      "10059\n",
      "1242990\n",
      "milton-paradise.txt\n",
      "96825\n",
      "1851\n",
      "468220\n",
      "shakespeare-caesar.txt\n",
      "25833\n",
      "2163\n",
      "112310\n",
      "shakespeare-hamlet.txt\n",
      "37360\n",
      "3106\n",
      "162881\n",
      "shakespeare-macbeth.txt\n",
      "23140\n",
      "1907\n",
      "100351\n",
      "whitman-leaves.txt\n",
      "154883\n",
      "4250\n",
      "711215\n"
     ]
    }
   ],
   "source": [
    "for files in gutenberg.fileids():\n",
    "    print(files)\n",
    "    print(len(gutenberg.words(files)))\n",
    "    print(len(gutenberg.sents(files)))\n",
    "    print(len(gutenberg.raw(files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c41d8",
   "metadata": {},
   "source": [
    "### NLTK BOOK\n",
    "- texts = [text1,...]\n",
    "-> text1-9 -> str 'text1'로 표현함\n",
    "-> text1에 기능을 부여함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2170b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.book text 1-9\n",
    "from nltk.book import*\n",
    "nltk.download('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ade47da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text1',\n",
       " 'text2',\n",
       " 'text3',\n",
       " 'text4',\n",
       " 'text5',\n",
       " 'text6',\n",
       " 'text7',\n",
       " 'text8',\n",
       " 'text9']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [f'text{i}' for i in range(1,10)]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1624328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = gutenberg.words(fileids='whitman-leaves.txt')\n",
    "fdist = nltk.FreqDist([w for w in corpus1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b766e",
   "metadata": {},
   "source": [
    "### brown\n",
    "-categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b4ec9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#from.nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "brown_corpus = nltk.corpus.brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d709017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_corpus.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### modal verbs의 쓰임\n",
    "modals = ['can','could','may','might','will','would']\n",
    "\n",
    "fdist_brown = nltk.FreqDist([w] for w in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f297d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditional frequency distribution (CFD)\n",
    "-조건이 붙은 fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c49547",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    #genre에 따른 fdist\n",
    "    (genre, word)\n",
    "    for genre in brown_corpus.categories()\n",
    "    for word in brown_corpus.words(categories=genre)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd01cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd('adventure')['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7dd889",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd('adventure').most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd.tabulate(conditions=brown_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
